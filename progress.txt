https://youtu.be/yQ20jZwDjTE

1시간 00분 08초

[웹 스크래핑 변경사항]
1. "티스토리"는 UserAgent 를 변경하지 않아도 정상적으로 html 을 받아옵니다.

2. "네이버"는 로그인 시도 시 자동입력방지 문자 입력 페이지가 뜹니다. 우회방법으로 자바스크립트를 이용하는 방법이 소개된 링크를 참고해주세요.
https://jaeseokim.github.io/Python/python-Selenium을-이용한-웹-크롤링-Naver-login-후-구독-Feed-크롤링/

3. "쿠팡" 강의 내용 확인 결과 일부 항목이 웹에서 접근했을 때와는 조금 다르게 가져오는듯 합니다. 확인 결과 화면 중 약 80% 는 정상, 20%는 페이지에 존재하지 않는 값을 가져옵니다. (어쩌면 다음 페이지에 나오는 내용일 수도 있습니다) 또한 80% 의 항목도 웹 페이지와는 달리 순서가 조금 뒤죽박죽 섞인듯 보입니다. requests  만 써서 가져왔을 때 쿠팡에서 반환해주는 값에 차이가 있는듯한데,  selenium 을 통한 결과를 비교해볼 필요가 있어 보이네요. 수업 시간에 결과 내용에 대해 전수 검사를 해볼 생각을 미처 해보지 못하여 내용에 오류가 있었던 점, 진심으로 사과 드립니다. 그리고 추가적으로 header를 만들때 항목으로 "Accept-Language": "ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3"를 추가해야 작동합니다.

4. "프로젝트" 강의 내용 중 네이버 뉴스를 가져올 때 500 Server Error 가 나고 있습니다. 이 때는 requests 에 headers 로 여러분 PC 의 user-agent 를 넣어주시면 됩니다.
(예시)
def create_soup(url):
    headers = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36"}

    res = requests.get(url, headers=headers)
    res.raise_for_status()    

    soup = BeautifulSoup(res.text, "lxml")
    return soup


-----------------------------------------------------------------------------

아래 블로그에서 소스코드를 받으실 수 있습니다. 
https://nadocoding.tistory.com/10